{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80532aff-d6d7-4bc2-a46d-e4b9fe2f474b",
   "metadata": {},
   "source": [
    "# TG Raman process code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6156c-054e-4313-b480-00e540abe7f8",
   "metadata": {},
   "source": [
    "Declare relevant Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cc5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.signal import find_peaks\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4babc85-cf2b-426e-abd0-08f318c3271b",
   "metadata": {},
   "source": [
    "Identifies files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0a2c30-f075-46fa-bcbd-1474cf577c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfilter = lambda file: os.path.splitext(file)[1] == \".csv\" #selects only the csv files\n",
    "csv_files = [f for f in os.listdir() if myfilter(f)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45939e-3242-42da-8264-f302da2767b4",
   "metadata": {},
   "source": [
    "Declares functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93877a1-d648-48b5-9a0e-2ce76145cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calibration(f,raw_data):\n",
    "#Reads in file to acquire calibration shift\n",
    "    with open(f) as fd:\n",
    "        reader = csv.reader(fd)\n",
    "        Cal_Line = [row for idx, row in enumerate(reader) if idx ==13]\n",
    "    \n",
    "    Cal_Delta = str(Cal_Line)[22:30] #Pulls out calibration factor from raw data file line 13\n",
    "    #print(Cal_Delta)\n",
    "    # Wavenumber correction\n",
    "    raw_data.iloc[:,[0]] +=float(Cal_Delta)\n",
    "    \n",
    "    return raw_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd56272-a4e8-4db2-8c47-23ea5b9ed7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs the time gating and snips data to desired wavenumber range\n",
    "def declare_snip(df, StartTG,EndTG,StartWN_snip_one,EndWN_snip_one): \n",
    "    \n",
    "    times = list(df.columns.values)\n",
    "    time_range = np.array(times, dtype=float)\n",
    "\n",
    "    wave_num = df.index\n",
    "    wave_num = np.asarray(wave_num, dtype=np.float32)\n",
    "    \n",
    " #find index location of begining of time gate snip\n",
    "    for i in range(0,len(time_range)):\n",
    "        dif_1 = time_range[i] - StartTG \n",
    "        if dif_1 >= 0:\n",
    "            start_snip = i  + 1 # +1 accounts for python read in eg 1:4 reads in 1,2,3\n",
    "            break\n",
    "        \n",
    "#find index location of end of time gate snip\n",
    "    for i in range(0,len(time_range)):  \n",
    "        dif_2 = time_range[i] - EndTG\n",
    "        if dif_2 >= 0:\n",
    "            end_snip = i + 1 # +1 accounts for python read in eg 1:4 reads in 1,2,3\n",
    "            break\n",
    "            \n",
    "#TG_snip grabs the time range desired for time gating\n",
    "    TG_snip = df[df.columns[start_snip : end_snip]]\n",
    "    \n",
    "#Target_snip is a dataframe with xy data, (wavenumber,averaged intensity data for snip region)\n",
    "    Target_snip = TG_snip.mean(axis=1)\n",
    "    \n",
    "#Rename intensity column\n",
    "    Target_snip.name = \"intensity\"\n",
    "\n",
    "#find location of start of wavenumber snip \n",
    "    for i in range(0,len(wave_num)):  \n",
    "        dif_1 = wave_num[i] - StartWN_snip_one\n",
    "        if dif_1 >= 0:\n",
    "            WNstart_snip_one = i + 1 #time_range.index(i)+1 # +1 accounts for python read in eg 1:4 reads in 1,2,3\n",
    "            break\n",
    "#find location of end of wavenumber snip \n",
    "    for i in range(0,len(wave_num)): \n",
    "        dif_3 = wave_num[i] - EndWN_snip_one\n",
    "        if dif_3 >= 0:\n",
    "            WNend_snip_one = i + 1 #time_range.index(i)+1 # +1 accounts for python read in eg 1:4 reads in 1,2,3\n",
    "            break\n",
    "    \n",
    "    Target_snip = Target_snip.iloc[WNstart_snip_one:WNend_snip_one]\n",
    "\n",
    "#Normalize Data\n",
    "    Target_snip = Target_snip / Target_snip.abs().max()\n",
    "\n",
    "    return Target_snip, StartTG, EndTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0651b927-5068-4ba1-b9f4-57c2813a78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script will generate a folder containing a plot of each data file in the folder. df is Target_snip from the declare_snip function\n",
    "def Spectra_plot(df,sample_name):\n",
    "#Plotting\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(df)\n",
    "    ax.set_title(os.path.splitext(sample_name)[0]) #Sets the title of plot to title of the csv file\n",
    "    plt.xlabel(\"Raman shift ($\\mathregular{cm^{-1}}$)\", labelpad=2) #labelpad=10 adjusts space between axis lable and plot\n",
    "    plt.ylabel(\"intensity\", labelpad=10)\n",
    "    \n",
    "#PLOT AESTHETICS\n",
    "    #set font sizes\n",
    "    S_size = 12\n",
    "    M_size = 14\n",
    "    L_size = 16\n",
    "\n",
    "    plt.rc('font', size= S_size)         # controls default text sizes\n",
    "    plt.rc('axes', titlesize= M_size)    # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize= M_size)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize= S_size)   # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize= S_size)   # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize= S_size)   # legend fontsize\n",
    "    plt.rc('figure', titlesize= L_size)  # fontsize of the figure title\n",
    "    \n",
    "#Export plots\n",
    "    #next 2 lines create a new folder in current folder to store plots\n",
    "    directory = \"plots\"\n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "    filename = os.path.splitext(sample_name)[0] + \".png\"\n",
    "    path = os.path.join(directory, filename)\n",
    "    fig.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6e7d0c-df6d-496e-a74a-686a0a463631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the spectral background\n",
    "#derived from stackoverflow code written for python 3.6:  https://stackoverflow.com/questions/29156532/python-baseline-correction-library -- Source: \"Baseline Correction with Asymmetric Least Squares Smoothing\" Paul H. C. Eilers Hans F.M. Boelens. Download access at- https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/dd7c1919-302c-4ba0-8f88-8aa61e86bb9d\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# y is the signal of length L, z is the fitted baseline\n",
    "# D is the difference matrix assuming a second order difference matrix\n",
    "# w is a weighted vector (currently un weighted e.g. all ones) if peak regions are known, can be set to zero in those regions adjusted in last boolean statment over iterations\n",
    "# W is a diagonal matrix with w on its diagonal, lam adjusts the balance between terms\n",
    "#p is the asymmetry parameter - recommended set between 0.001-0.1\n",
    "#lam: 10^4 to 10^6 are a good starting point\n",
    "\n",
    "def baseline_als(y, lam, p, niter=10):\n",
    "    L = len(y)\n",
    "  #constructs a sparse matrix from diagonals\n",
    "    D = sparse.diags([1,-2,1],[0,-1,-2], shape=(L,L-2))\n",
    "    w = np.ones(L)\n",
    "    i = 0\n",
    "    for i in range(niter):\n",
    "        W = sparse.spdiags(w, 0, L, L)\n",
    "    # z solves for the optimization of the statement with Z intermediate\n",
    "        Z = W + lam * D.dot(D.transpose())\n",
    "        z = spsolve(Z, w*y)\n",
    "        w = p * (y > z) + (1-p) * (y < z)\n",
    "    #peakfind identifies where peaks are (assigned zero value) and where the absence of peask (assigned 1 value)\n",
    "    #sensitivity value 0.02 was tuned using the level of noise in a test image and may need to be adjusted\n",
    "        peakfind = (y - z > 0.02) * 0 + (y-z <= 0.02) * 1\n",
    "        \n",
    "    return z, peakfind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0816870-e05a-4c50-9fec-9b5a756c938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifies the longest run in Raman spectra with no peaks. Used in Signal-to-Background Ratio (SBR) calculation\n",
    "def run_length(vals, max_length = 500):\n",
    "    best_length = 0\n",
    "    current_length = 0\n",
    "    i = 0\n",
    "    range_end = 0\n",
    "    for (i, t) in enumerate(vals):\n",
    "        if t == 1:\n",
    "            current_length += 1\n",
    "            if current_length > best_length:\n",
    "                range_end = i\n",
    "                best_length = current_length\n",
    "            if current_length == max_length:\n",
    "                range_end = i\n",
    "                break\n",
    "        else:\n",
    "            current_length = 0\n",
    "\n",
    "    return best_length, range_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c719880-815c-4511-8f76-11d0c8bfb8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates Signal-to-Background Ratio (SBR)\n",
    "def SBRcalc(df):\n",
    "    base, ispeak = baseline_als(df, 10e5,0.01,niter=15)\n",
    "#background subtracted data - to determine height of tallest peak above fitted background\n",
    "    y = df-base\n",
    "    \n",
    "#find a long run with no peaks\n",
    "    min_length = 100\n",
    "    troughs = ispeak.values\n",
    "    best_length, range_end = run_length(troughs, max_length = 500)\n",
    "    \n",
    "    if best_length < min_length:\n",
    "        #if there is not sufficient region found to have 'no peaks' it is assumed that\n",
    "        #the range is primarily background or broad peaks where the noise can be accessible without too many peak outliers\n",
    "        run = df       \n",
    "    else:\n",
    "        range_begin = range_end - best_length + 50\n",
    "        no_peaks = df.iloc[range_begin:range_end]\n",
    "        run = no_peaks\n",
    "        \n",
    "    fit,toss = baseline_als(run, 10e4,0.5,niter=15)\n",
    "    flat_noise = run - fit\n",
    "   \n",
    "    error_STD = flat_noise.std()\n",
    "#SBR = height above baseline of max peak / STD of background --- 2*STD =95% confidence interval\n",
    "    sbr = y.max()/(2*error_STD)\n",
    "    \n",
    "#bins the error into a histogram\n",
    "    #flat_noise.hist()\n",
    "#plots in window to confirm fit\n",
    "    #no_peaks.plot()\n",
    "    #plt.plot(flat_noise.index,fit)\n",
    "    \n",
    "    return sbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79f0d4c-ef54-4f6c-a59f-87f8f3bad12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exports text data and metadata details:\n",
    "def details_CSV(df,sample_name, StartTG_snip, EndTG_snip, sbr, snr):\n",
    "# Adjust name\n",
    "    Read_in_Name = os.path.splitext(sample_name)[0]\n",
    "    Sample_Name = Read_in_Name[:-7]\n",
    "# writing metadata to csv\n",
    "    directory = \"Final Processed Files\"\n",
    "    os.makedirs(directory, exist_ok = True)\n",
    "    filename = Sample_Name + \"_Proc\" + \".csv\"\n",
    "    path = os.path.join(directory, filename)\n",
    "\n",
    "# Metadata content options \n",
    "#1. sample name\n",
    "    name = (\"Sample: \" + Sample_Name + \"\\n\")\n",
    "#2. normalization protocol\n",
    "    norm_proc = \"Intensity data was averaged across the time gated region (df.mean(axis=1)) followed by normalization by dividing the whole range by the absolute value of the highest point\\n\"\n",
    "#3. gating snip\n",
    "    snip_range = ('The time gated region is ' + str(StartTG_snip) + ' - ' + str(EndTG_snip) + ' ns\\n')\n",
    "#4. Signal to background -reference to self\n",
    "    SBR_read = (f'The signal to background ratio (SBR) is: {sbr}\\n')\n",
    "    \n",
    "# open file to write  \n",
    "# 'w' indicates that the file is open to 'write' mode\n",
    "    with open(path, 'w') as csvfile:  \n",
    "    # creating a csv writer object  \n",
    "        csvwriter = csv.writer(csvfile)  \n",
    "\n",
    "# Print to file \n",
    "    #1. sample name\n",
    "        csvfile.write (name)\n",
    "    #2. normalization protocol\n",
    "        csvfile.write(norm_proc)\n",
    "    #3. gating snip\n",
    "        csvfile.write(snip_range) \n",
    "    #4. Signal to background -reference to self\n",
    "        csvfile.write(SBR_read)\n",
    "    #5. Signal to noise - reference to dupicate spectra with same first part of name \n",
    "        if (snr > 0):\n",
    "            SNR_read = ('The signal to noise ratio (SNR) is: '+ str(snr) + '\\n')\n",
    "            csvfile.write(SNR_read)\n",
    "\n",
    "    #insert xy data\n",
    "    df.to_csv(path, mode='a', sep=';')\n",
    "    \n",
    "    path = os.path.join(directory, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c42ecbda-c787-4291-a234-71ea873fc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk 1: Reads in csv files and initiates calibration\n",
    "def Chunk_1(fname,start_snip,end_snip,StartWN_snip_one,EndWN_snip_one):\n",
    "# Reads raw time gate Raman data into a Pandas dataframe\n",
    "    df = pd.read_csv(fname, sep = ';', skiprows=15)\n",
    "    \n",
    "# Wavenumber calibration\n",
    "    df = Calibration(fname,df)\n",
    "    \n",
    "# Renames first column and set to index\n",
    "    df.rename(columns = {\"NaN\": \"cm-1\"}, inplace = True)\n",
    "    df.set_index(\"cm-1\", inplace = True, drop=True)\n",
    "\n",
    "# declare_snip snips data to declared gating region and wavenumber window, averages it to 2D spectra and normalizes data between 0-1 intensity\n",
    "    \n",
    "    Target_snip, StartTG_snip, EndTG_snip = declare_snip(df,start_snip,end_snip,StartWN_snip_one,EndWN_snip_one) # update in format of declare_snip(StartTG_snip,EndTG_snip) in nanoseconds\n",
    "    \n",
    "    return Target_snip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b2b35-4284-4386-90d2-58310e4891b4",
   "metadata": {},
   "source": [
    "Runs the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8c9077-e5b4-4453-bf3e-0ba8f0a25392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the desired snip region -- 5.5 ns - 5.8 ns works well for the plasticizer data library\n",
    "StartTG_snip = 5.5 \n",
    "EndTG_snip = 5.8 \n",
    "\n",
    "# Declare wavenumber snip region - the function will identify the index of values closest to the input values\n",
    "StartWN_snip_one = 120  # for SNR calculation, set StartWN_snip > 400 to cut out the Rayleigh-wing\n",
    "EndWN_snip_one = 2500\n",
    "\n",
    "# Declares variables to calculate SNR from duplicate data\n",
    "current_name = []\n",
    "current_spectra = []\n",
    "current_base = []\n",
    "current_peaks = []\n",
    "old_name = []\n",
    "old_spectra = []\n",
    "# Allows commenting out SBR, SNR calculation sections if not needed\n",
    "# SBR = 0\n",
    "# SNR = 0\n",
    "\n",
    "# Reads in the csv files one at a time and isolates the snipped region, adjusts wavenumbers for instrument calibration error\n",
    "for f in csv_files:\n",
    "    # Averages over the snipped region, normalizes data, and returns \n",
    "    current_spectra = Chunk_1(f, StartTG_snip, EndTG_snip, StartWN_snip_one,EndWN_snip_one)\n",
    "    # Creates a new folder called Plots and creates PNG plots of all the spectra in the folder\n",
    "    Spectra_plot(current_spectra,f)\n",
    "    # Calculates Signal-to-Background Ratio\n",
    "    SBR = SBRcalc(current_spectra)\n",
    "    \n",
    "    # Calculates SNR for data in duplicate as the code iterates through the files in the list\n",
    "    current_name = f[:-14] #cuts off file type and unique identifiers\n",
    "    \n",
    "    if (current_name == old_name):\n",
    "        # Performs background subtraction on the current spectra and previous spectra if sample name is the same compound\n",
    "        current_base, current_peaks = baseline_als(current_spectra, 10e5,0.01,niter=15)\n",
    "        old_base, old_peaks = baseline_als(old_spectra, 10e5,0.01,niter=15)\n",
    "        cur_spec_bkgsub = current_spectra - current_base\n",
    "        old_spec_bkgsub = old_spectra - old_base\n",
    "\n",
    "        # Finds major peak in the spectra and selects a range of 24 wavenumber about the peak\n",
    "        peaks, _ = find_peaks(current_spectra,height = 0.95) # finds the most significant peak in the spectra. height = 0.95 accomodates for background subtraction of normalized spectra\n",
    "        bumped = cur_spec_bkgsub.reset_index()\n",
    "        wavenum = bumped.iloc[:,0]\n",
    "        S_Range= wavenum.iloc[peaks] -12\n",
    "        E_Range = wavenum.iloc[peaks]+12\n",
    "\n",
    "        # Subtracts the baseline corrected spectra of successive replicates within the region about the major peak\n",
    "        Subtracted =  cur_spec_bkgsub.subtract(old_spec_bkgsub)\n",
    "        Noise = Subtracted.loc[S_Range.iloc[0]:E_Range.iloc[0]]\n",
    "\n",
    "        # Calculates standard deviation of the noise in the region under the major peak and calculates average height of the major peak between successive spectra\n",
    "        Noise_STD = np.std(Noise.to_numpy())\n",
    "        current_peak = cur_spec_bkgsub.max()\n",
    "        old_peak = old_spec_bkgsub.max()\n",
    "        peaks = [current_peak, old_peak]\n",
    "        Ave_peak = np.mean(peaks)\n",
    "\n",
    "        # Calculates SNR based on McCreery 2000 Chap. 4\n",
    "        SNR = Ave_peak/(Noise_STD/np.sqrt(2))\n",
    "    else:\n",
    "        old_name = current_name\n",
    "        old_spectra = current_spectra\n",
    "        SNR = 0\n",
    "    \n",
    "    details_CSV(current_spectra,f, StartTG_snip, EndTG_snip, SBR, SNR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0cf34a-612a-49da-8212-b5abc1fcbe3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
